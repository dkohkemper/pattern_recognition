{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconocimiento de Patrones - Proyecto final**\n",
    "# Reconocimiento de letras del alfabeto inglés\n",
    "# Ing. Daniel Kohkemper\n",
    "\n",
    "________________________________________________________________________________________________\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "El archivo de datos de este proyecto fue creado en 1991 por David Slate [1]. El mismo consiste en un conjunto de valores estadísticos obtenidos de imágenes rectangulares en blanco y negro de las 26 letras del alfabeto inglés y cada imagen fue levemente distorsionada. Los datos no presentan valores faltantes y vienen en formato numérico (no existen valores categóricos), lo cual facilita mucho el preprocesamiento de los mismos. \n",
    "\n",
    "Existen 20.000 muestras del alfabeto inglés, lo cual da un promedio de 769 muestras por letra. Se utilizaron 20 tipos de fuente diferentes, con 5 tipos diferentes de trazo y 6 tipos diferentes de letras, generados de manera aleatoria siguiendo una distribución uniforme.\n",
    "\n",
    "En 1991, este problema se consideraba uno difícil, debido a ''la amplia diversidad de fuentes y la naturaleza primitiva de los datos''. En el trabajo de Slate [2] se encuentra el proceso de obtención de los datos de manera más detallada, el cual en la actualidad se puede describir como un trabajo de la rama del Procesamiento de Imágenes. Un ejemplo de las letras utilizadas se puede observar en la siguiente figura:\n",
    "\n",
    "![Título](fig/letras_ex.png)\n",
    "\n",
    "Para cada imagen, se obtuvieron diferentes métricas y estadísticas, las cuales fueron normalizadas en un rango de 0 a 15 descritas a continuación. \n",
    "\n",
    "1.\tlettr\tLetra mayúscula\t(26 valores de A a Z) \n",
    "2.\tx-box\tposición horizontal de la imagen\n",
    "3.\ty-box\tposición vertical de la imagen\n",
    "4.\twidth\tancho de la imagen en pixeles\n",
    "5.\thigh    alto de la imagen en pixeles\n",
    "6.\tonpix\t# total de pixeles en el caracter\n",
    "7.\tx-bar\tmedia horizontal (x) de pixeles encendidos\n",
    "8.\ty-bar\tmedia vertical (y) de pixeles encendidos\n",
    "9.\tx2bar\tmedia cuadrática horizontal de 7.\n",
    "10.\ty2bar\tmedia cuadrática vertical de 8.\n",
    "11.\txybar\tmedia de correlación x y\n",
    "12.\tx2ybr\tmedia de x * x * y \n",
    "13.\txy2br\tmedia de x * y * y\n",
    "14.\tx-ege\tvalor medio de bordes de izq a der\n",
    "15.\txegvy\tcorrelación de bordes en x con y\t\n",
    "16.\ty-ege\tvalor medio de bordes de abajo hacia arriba\n",
    "17.\tyegvx\tcorrelación de bordes en y con x\n",
    "\n",
    "El conjunto de datos fue utilizado en un estudio realizado por D. Slate, que utiliza un sistema de clasificación adaptativa basado en aquel de J.H. Holland, el cual consiste en la creación de una lista de reglas condición-acción (clasificadores) que son aplicadas en paralelo a un conjunto de mensajes (entradas).\n",
    "\n",
    "El sistema consiste en los siguientes pasos:\n",
    "\n",
    "1. Un algoritmo de desempeño que compara las reglas con los mensajes para determinar cuáles reglas deben ser activadas.\n",
    "2. Un algoritmo de reforzamiento que modifica el puntaje o fuerza de cada regla.\n",
    "3. Un algoritmo que crea reglas que generaliza ejemplares o combina reglas para crear nuevas.\n",
    "\n",
    "El aprendizaje del sistema se realizó mediante la separación del set de datos de 20.000 en 16.000 datos de entrenamiento y 4.000 de prueba, lo que representa un porcentaje de 80%-20%. El programa se corrió 5 veces con el set de entrenamiento (se presupone una cross-validación) en lo que se crearon nuevas reglas, se descartaron las insatisfactorias y se modificaron las estadísticas respectivamente de cada regla. De esta manera se logró expandir el conjunto de pruebas a 80.000. La sexta pasada se realizó sin generar nuevas reglas, y aquellas que no lograron cumplir los niveles de desempeño pre-establecidos fueron descartadas. Finalmente, se estimuló el sistema con el set de prueba para determinar el nivel global de desempeño del sistema, en el cual no se generaron ni modificaron reglas, sino que se obtuvieron las métricas de desempeño finales.\n",
    "\n",
    "El sistema de clasificación se describe a continuación:\n",
    "\n",
    "1. Comparar el vector de atributos de un ítem de prueba (muestra) con los atributos especificados para cada clasificador en la regla actual.\n",
    "2. Seleccionar un set que se ajuste [M] que consiste en todos los clasificadores cuyas condiciones son satisfechas por el vector de atributos de la muestra.\n",
    "3. Calcular un puntaje (o apuesta) para cada clasificador del set M. Asignar la categoría asociada con el puntaje máximo como salida del sistema.\n",
    "4. Si se está en fase de aprendizaje, modificar las estadísticas de desempeño de uno o más clasificadores como es especificado por el sistema de puntajes.\n",
    "5. Si se está en la fase de aprendizaje, descartar las reglas débiles y crear nuevas reglas de acuerdo al algoritmo de creación de reglas.\n",
    "6. Seleccionar el siguiente ítem de prueba (muestra) y repetir el proceso.\n",
    "\n",
    "De manera resumida, el sistema de codificación de atributos utiliza tres métodos distintos: binario (BIN), codificación Gray (GRA) y entero (INT). El sistema de creación de reglas se realiza por medio de varios métodos: aleatorio (RAN), híbrido (HYB), \n",
    "mutación (MUT), combinación de dos reglas (CROSS) y generalización basada en ejemplos (EXM). Una explicación más detallada de estos procedimientos además del sistema de puntaje puede revisarse en [2].\n",
    "\n",
    "La investigación reporta un porcentaje de correcta clasificación de muestras de la siguiente manera:\n",
    "\n",
    "1. Binario:   43,2% - 54,7%\n",
    "2. Gray Code: 45,9& - 59,3%\n",
    "3. Entero:    70,4% - 80,0%\n",
    "\n",
    "### Aprendizaje de máquina basado en reglas\n",
    "\n",
    "Esta rama abarca cualquier método que identifica, aprende o evoluciona un conjunto de reglas. El conocimiento completo del sistema se basa en las relaciones que se puedan hacer entre los datos de entrada con sus salidas por medio del conjunto de reglas. Estos sistemas dependen de conocimiento contextual de la semántica de los datos, por lo que su uso no es universal y aplica dentro del propio significa de los datos. Típicamente, las reglas se generan en la forma IF ... THEN, es decir, condición y resultado.\n",
    "\n",
    "Estos sistemas tienen alguna semejanza con los árboles de decisión, así como también poseen varias diferencias. En los sistemas basados en reglas, se puede hacer un enfoque top-down o bottom-up con el que se puede llegar a una clasificación de lo general a lo particular o viceversa. Los árboles de búsqueda siguen más bien una direción top-down. Por otro lado, en un sistema de reglas, estas son generadas por un humano, mientras que en un árbol se generan a partir de las propiedades estadísticas y la distribución de los datos. Usualmente se decide usar la última cuando el sistema es muy complejo de entender para poder crear las reglas de manera manual, las cuales dependen de la habilidad del diseñador de poder describir enteramente el problema.\n",
    "\n",
    "### Conclusiones preliminares sobre el estudio\n",
    "\n",
    "Se observa que este estudio tiene casi 30 años de haberse realizado, lapso en el cual las metodologías y tecnologías de reconocimiento de patrones y aprendizaje supervisado han avanzado bastante. El método de clasificación por reglas es poco utilizado actualmente, con lo que sería un buen caso de estudio probar el set de datos con métodos más utilizados recientemente, e incluso por medio de redes neuronales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Aunque se indicó anteriormente que el set de datos es bastante íntegro y no posee valores faltantes, se utiliza el código para eliminar datos faltantes. Se cargan además las bibliotecas básicas y se asignan los nombres de los atributos del set de datos así como la variable de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x_box</th>\n",
       "      <th>y_box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x_bar</th>\n",
       "      <th>y_bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x_ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y_ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  x_box  y_box  width  high  onpix  x_bar  y_bar  x2bar  y2bar  xybar  \\\n",
       "0      T      2      8      3     5      1      8     13      0      6      6   \n",
       "1      I      5     12      3     7      2     10      5      5      4     13   \n",
       "2      D      4     11      6     8      6     10      6      2      6     10   \n",
       "3      N      7     11      6     6      3      5      9      4      6      4   \n",
       "4      G      2      1      3     1      1      8      6      6      6      6   \n",
       "5      S      4     11      5     8      3      8      8      6      9      5   \n",
       "6      B      4      2      5     4      4      8      7      6      6      7   \n",
       "7      A      1      1      3     2      1      8      2      2      2      8   \n",
       "8      J      2      2      4     4      2     10      6      2      6     12   \n",
       "9      M     11     15     13     9      7     13      2      6      2     12   \n",
       "\n",
       "   x2ybr  xy2br  x_ege  xegvy  y_ege  yegvx  \n",
       "0     10      8      0      8      0      8  \n",
       "1      3      9      2      8      4     10  \n",
       "2      3      7      3      7      3      9  \n",
       "3      4     10      6     10      2      8  \n",
       "4      5      9      1      7      5     10  \n",
       "5      6      6      0      8      9      7  \n",
       "6      6      6      2      8      7     10  \n",
       "7      2      8      1      6      2      7  \n",
       "8      4      8      1      6      1      7  \n",
       "9      1      9      8      1      1      8  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Se apagan los warnings para evitar las alertas de posibles cambios de versión en Python3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "\n",
    "# URL address of data set\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
    "\n",
    "# Define header of dataset, obtain this information from dataset information\n",
    "header = ['letter', 'x_box', 'y_box', 'width','high','onpix','x_bar','y_bar','x2bar','y2bar','xybar','x2ybr','xy2br','x_ege','xegvy','y_ege', 'yegvx']\n",
    "\n",
    "# load dataset as csv file\n",
    "df = pd.read_csv(\"data/letter_recognition.data\",header=None,names=header)\n",
    "\n",
    "# if dataset has '?' in it, convert these into NaN\n",
    "df = df.replace('?', np.nan)\n",
    "# drop the NaN\n",
    "df = df.dropna(axis=0, how=\"any\")\n",
    "\n",
    "# Print some values of the data set\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el manejo y graficación de los datos, se reducirá el set de datos temporalmente a las 5 vocales del alfabeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>x_box</th>\n",
       "      <th>y_box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x_bar</th>\n",
       "      <th>y_bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x_ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y_ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>O</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>E</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   letter  x_box  y_box  width  high  onpix  x_bar  y_bar  x2bar  y2bar  \\\n",
       "1       I      5     12      3     7      2     10      5      5      4   \n",
       "7       A      1      1      3     2      1      8      2      2      2   \n",
       "11      O      6     13      4     7      4      6      7      6      3   \n",
       "16      O      3      4      4     3      2      8      7      7      5   \n",
       "23      O      6     11      7     8      5      7      6      9      6   \n",
       "36      O      4      7      5     5      3      7      7      8      6   \n",
       "39      E      3      4      3     6      2      3      8      6     10   \n",
       "41      E      3      7      4     5      4      7      7      5      8   \n",
       "62      E      6      9      4     4      2      7      7      4      7   \n",
       "67      E      2      3      3     2      2      7      7      5      7   \n",
       "\n",
       "    xybar  x2ybr  xy2br  x_ege  xegvy  y_ege  yegvx  \n",
       "1      13      3      9      2      8      4     10  \n",
       "7       8      2      8      1      6      2      7  \n",
       "11     10      7      9      5      9      5      8  \n",
       "16      7      6      8      2      8      3      8  \n",
       "23      7      5      9      4      8      5      5  \n",
       "36      7      6      8      3      8      3      8  \n",
       "39      7      6     15      0      8      7      8  \n",
       "41      8      8      9      3      9      6      9  \n",
       "62     10      6     10      1      9      7      9  \n",
       "67      7      6      8      2      8      5     10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df.letter == 'A') | (df.letter == 'E') | (df.letter == 'I') | (df.letter == 'O') | (df.letter == 'U')]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, ..., 3, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Make a list of features only\n",
    "features = ['x_box', 'y_box', 'width','high','onpix','x_bar','y_bar','x2bar','y2bar','xybar','x2ybr','xy2br','x_ege','xegvy','y_ege', 'yegvx']\n",
    "\n",
    "# Separate features from class(es)\n",
    "input_features = df.loc[:,features].values\n",
    "output_class   = df.loc[:,['letter']].values\n",
    "# Squeeze output into one single column\n",
    "output_class = output_class.ravel()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "output_class[:] = le.fit_transform(output_class[:])\n",
    "\n",
    "output_class\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate data intro training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_features, output_class, test_size=0.20, random_state=50)\n",
    "\n",
    "output_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis explotorio de datos\n",
    "\n",
    "Antes de proceder con el aprendizaje automático, se realiza un análisis exploratorio de los datos por medio de gráficas y aprendizaje no supervisado para poder tener más información y sentido del set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.DataFrame.hist(df, figsize = [20,20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje con Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Numpy, TensorFlow, TFLearn, and MNIST data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 12,  3, ...,  8,  4, 10],\n",
       "       [ 1,  1,  3, ...,  6,  2,  7],\n",
       "       [ 6, 13,  4, ...,  9,  5,  8],\n",
       "       ...,\n",
       "       [ 4,  3,  5, ...,  8,  4,  8],\n",
       "       [ 4,  9,  5, ...,  8,  5,  5],\n",
       "       [ 4,  9,  6, ...,  7,  2,  8]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, ..., 3, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate data intro training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_features, output_class, test_size=0.20, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, 16])\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 5, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "# Define model\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: X5ITMT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 2791\n",
      "Validation samples: 311\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (10,) for Tensor 'TargetsData/Y:0', which has shape '(?, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-577d6168a2e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3_clone\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3_clone\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    337\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                                                        show_metric)\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                             \u001b[1;31m# Update training state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3_clone\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[1;32m--> 818\u001b[1;33m                                              feed_batch)\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;31m# Retrieve loss value from summary string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3_clone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py3_clone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (10,) for Tensor 'TargetsData/Y:0', which has shape '(?, 5)'"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(x_train, y_train, validation_set=0.1, show_metric=True, batch_size=10, n_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "\n",
    "# Download the Titanic dataset\n",
    "from tflearn.datasets import titanic\n",
    "titanic.download_dataset('titanic_dataset.csv')\n",
    "\n",
    "# Load CSV file, indicate that the first column represents labels\n",
    "from tflearn.data_utils import load_csv\n",
    "data, labels = load_csv('titanic_dataset.csv', target_column=0,\n",
    "                        categorical_labels=True, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(data, columns_to_ignore):\n",
    "    # Sort by descending id and delete columns\n",
    "    for id in sorted(columns_to_ignore, reverse=True):\n",
    "        [r.pop(id) for r in data]\n",
    "    for i in range(len(data)):\n",
    "      # Converting 'sex' field to float (id is 1 after removing labels column)\n",
    "      data[i][1] = 1. if data[i][1] == 'female' else 0.\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "# Ignore 'name' and 'ticket' columns (id 1 & 6 of data array)\n",
    "to_ignore=[1, 6]\n",
    "\n",
    "# Preprocess data\n",
    "data = preprocess(data, to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.    ,   1.    ,  29.    ,   0.    ,   0.    , 211.3375],\n",
       "       [  1.    ,   0.    ,   0.9167,   1.    ,   2.    , 151.55  ],\n",
       "       [  1.    ,   1.    ,   2.    ,   1.    ,   2.    , 151.55  ],\n",
       "       ...,\n",
       "       [  3.    ,   0.    ,  26.5   ,   0.    ,   0.    ,   7.225 ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   0.    ,   7.225 ],\n",
       "       [  3.    ,   0.    ,  29.    ,   0.    ,   0.    ,   7.875 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, 6])\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 32)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 654  | time: 3.165s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 1308/1309\n",
      "Training Step: 655  | time: 3.170s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 1309/1309\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = tflearn.DNN(net)\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(data, labels, n_epoch=1, batch_size=2, show_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "[1] [Letter Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Letter+Recognition)\n",
    "\n",
    "[2] [Letter Recognition Using Holland-Style Adaptive Classifiers](http://www.cs.uu.nl/docs/vakken/mpr/Frey-Slate.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
