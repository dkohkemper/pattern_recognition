{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconocimiento de Patrones - Investigación Corta 3**\n",
    "# Modelos Ocultos de Markov aplicados a Machine Learning\n",
    "# Ing. Daniel Kohkemper\n",
    "\n",
    "________________________________________________________________________________________________\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "Ante de comenzar a hablar sobre el tema, es importante definir o refrescar algunos conceptos que provienen de la teoría de probabilidad [1], los cuales nos ayudarán a enteder mejor el concepto detrás de los Modelos Ocultos de Markov.\n",
    "\n",
    "Una variable aleatoria `X` es una variable cuyo valor probiene de un experimento aleatorio. De estos experimentos resultan las `observaciones`, cuyas posibles combinaciones de resultados conforman el `espacio muestreal`. Estos resultados, y la naturaleza del espacio muestreal puede ser continua o discreta. Por ejemplo, los resultados pueden ser los valores numéricos de las caras de un dado (de 1 a 6) o las dos caras de una moneda (escudo o corona). Se le llama `evento` a un subconjunto del espacio muestreal.\n",
    "\n",
    "Las probabilidades son números que van de 0 a 1, o bien de 0 a 100%. La `función de probabilidad` o `distribución de probabilidad`, distribuye la masa de probabilidad de 1 a lo largo del espacio muestreal. Se indica a `P(A)` la probabilidad de que el evento A suceda. La probabilidad de todos los posibles eventos debe ser igual a 1.\n",
    "\n",
    "Se define como `proceso aleatorio` o `proceso estocástico`, como una colección de variables aleatorias indexadas por un conjunto T, que puede ser discreto o continuo, con lo que puede representar instantes en el tiempo o número de experimento. También puede existir una independencia o dependencia en los experimentos. Por ejemplo, el resultado de tirar una moneda es independiente de todos los resultados anteriores, mientras que el precio en el mercado de valores depeden de condiciones anteriores.\n",
    "\n",
    "Para mayor contexto sobre definiciones y teoría de probabilidad, se recomienda consultar a fuentes más rigurosas y extensas.\n",
    "\n",
    "### 1.1 Aplicaciones\n",
    "\n",
    "1. Reconocimiento de voz\n",
    "2. Síntesis de voz\n",
    "3. Reconocimiento de escritura\n",
    "4. Traducción de máquina\n",
    "5. Criptoanálisis\n",
    "6. Computación financiera\n",
    "7. Alineamiento de bio-secuencias\n",
    "8. Predicción de genes\n",
    "9. Plegamiento de proteínas\n",
    "10. Modelización del transporte (forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo Oculto de Markov [2]\n",
    "\n",
    "### 2.1 Propiedad de Markov\n",
    "\n",
    "Se dice que un proceso estocástico cumple la `propiedad de Markov` si la distribución de probabilidad condicional de estados futuros depende únicamente de la información del estado presente. De esta manera, el sistema se dice que no posee memoria (*memoryless*) ya que el futuro no depende del pasado.\n",
    "\n",
    "Así mismo, un proceso estocástico que cumpla la propiedad de Markov se dice que es un `proceso o cadena de Markov`. Cabe mencionar que este proceso puede ser de tiempo continuo o discreto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modelo de Markov\n",
    "\n",
    "Una cadena de Markov es el modelo más simple que se puede tener, pero en el sentido más general se le puede llamar `Modelo De Markov`. Una definición más rigurosa podría ser un sistema que posee una función probabilística de un proceso de Markov. \n",
    "\n",
    "Es posible además obtener cuatro subsistemas dependiendo de si el sistema es autónomo o no (que no sea autónomo signfica que es parcialmente controlable) o que sea completa o parcialmente observable. \n",
    "\n",
    "Para la presente discusión interesan únicamente los modelos que son autónomos así como completamente observable (cadena de Markov o Modelo Visible de Markov) o parcialmente observable (Modelo Oculto de Markov)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Elementos del modelo\n",
    "\n",
    "1. Hay un número finito *N* de estados en el modelo, en donde la señal posee alguna propiedad mesurable y distintiva.\n",
    "\n",
    "2. En cada tiempo *t*, se entra a un estado nuevo basado en la distribución de probabilidad de transición, que depende del estado anterior (propiedad de Markov).\n",
    "\n",
    "3. Después de cada transición, se produce una observación basada en la probabilidad de distribución de la observación. La observación constituye un símbolo de salida.\n",
    "\n",
    "A continuación se describen los elementos de un HMM.\n",
    "\n",
    "![Título](fig/variables.gif)\n",
    "\n",
    "Se utiliza la notación compacta \n",
    "\n",
    "![Título](fig/model.gif)\n",
    "\n",
    "para representar un HMM, el cual involucra escoger la cantidad de estados N, la cantidad de observaciones M y las distribuciones de probabilidad de transición de estado (A), observación (B) y estado inicial (pi). Para la mayoría de aplicaciones, la distribución pi es la menos importante y usualmente se puede escoger un estado inicial fijo.\n",
    "\n",
    "Finalmente, el modelo se llama oculto ya que en muchas ocasiones, las transiciones son desconocidas (ocultas) y únicamente las observaciones son las visibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Los tres problemas de HMM\n",
    "\n",
    "Dada la descripción del HMM, se derivan tres problemas distitnos que permiten utilizar el modelo en aplicaciones prácticas.\n",
    "\n",
    "### 2.3.1 Problema 1: Evaluar\n",
    "\n",
    "Dada la secuencia de observaciones\n",
    "\n",
    "![Título](fig/observ_seq.gif)\n",
    "\n",
    "y el modelo\n",
    "\n",
    "![Título](fig/model.gif)\n",
    "\n",
    "cómo calcular la probabilidad de la secuencia de observación\n",
    "\n",
    "![Título](fig/prob_o_lambda.gif)\n",
    "\n",
    "#### Solución\n",
    "\n",
    "- Enumerar cada posible secuencia de estados de longitud T. Esta solución es irrealizable.\n",
    "- Procedimiento *forward-backward*.\n",
    "\n",
    "### 2.3.1 Problema 2: Descubrir\n",
    "\n",
    "Dada la secuencia de observaciones\n",
    "\n",
    "![Título](fig/observ_seq.gif)\n",
    "\n",
    "cómo escoger la secuencia de estados\n",
    "\n",
    "![Título](fig/state_seq2.gif)\n",
    "\n",
    "que es óptima en un sentido significativo\n",
    "\n",
    "#### Solución\n",
    "\n",
    "- Algoritmo de Viterbi. Los pasos para encontrar la mejor secuencia de estados es:\n",
    "\n",
    "1. Paso 1: Inicialización\n",
    "![Título](fig/vit1.gif)\n",
    "2. Paso 2: Recursión\n",
    "![Título](fig/vit2.gif)\n",
    "3. Paso 3: Terminación\n",
    "![Título](fig/vit3.gif)\n",
    "4. Paso 4: Backtrace\n",
    "![Título](fig/vit4.gif)\n",
    "\n",
    "### 2.3.1 Problema 3: Optimizar\n",
    "\n",
    "Cómo ajustar los parámetros del modelo\n",
    "\n",
    "![Título](fig/model.gif)\n",
    "\n",
    "para maximizar \n",
    "\n",
    "![Título](fig/prob_o_lambda.gif)\n",
    "\n",
    "#### Solución\n",
    "\n",
    "- Método Baum-Welsch\n",
    "- Método Expectation–Maximization  (EM)\n",
    "- Técnicas de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Caso de Uso\n",
    "\n",
    "El HMM se puede utilizar para implementar un esquema de reconocimiento de voz. Asuma que se cuenta con un un HMM de N estados para un vocabulario de V palabras. Mediante la cuantización vectorial (VQ) se representa la señal de habla mediante una serie de símbolos de un libro de códigos (codebook). \n",
    "\n",
    "Para la secuencia de entrenamiento, se utiliza para cada palabra de vocabulario, una serie de vocalizaciones de la palabra (por uno o múltiples locutores). Se utiliza la solución del **Problema 3** para obtener los parámetros óptimos del modelo para cada palabra.\n",
    "\n",
    "Para desarrollar un entendimiento físico de los estados del modelo, se utiliza la solución del **Problema 2**, para segmentar cada una de las secuencias de entrenamiento de cada palabra en estados, y seguidamente estudiar las observaciones realizadas en cada estado. Este estudio realiza mejoras en el modelo.\n",
    "\n",
    "Finalmente, para reconocer una palabra desconocida, se utiliza la solución del **Problema 1** para puntuar cada modelo de palabra basado en la secuencia de observaciones y seleccionar la palabra cuyo modelo puntúa más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementación del modelo en Python\n",
    "\n",
    "### 3.1 Modelo de Markov\n",
    "\n",
    "A continuación se implementará un simple modelo de Markov (visible) basado en [3]. Primeramente se importan las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente se definen los estados. Para este ejemplo, tomaremos el modelo de un perro que puede estar haciendo una de tres cosas; dormir, comer o jugar. Se declara el vector *pi* que guarda la probabilidad inicial, es decir, la probabilidad de comenzar en determinado estado. En general, la suma de las probabilidades tiene que ser igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping    0.35\n",
      "eating      0.35\n",
      "pooping     0.30\n",
      "Name: states, dtype: float64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# create state space and initial state probabilities\n",
    "\n",
    "states = ['sleeping', 'eating', 'pooping']\n",
    "pi = [0.35, 0.35, 0.3]\n",
    "state_space = pd.Series(pi, index=states, name='states')\n",
    "print(state_space)\n",
    "print(state_space.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente se genera la matriz A de distribución de probabilidad de transición de estado. La suma de las filas de esta matriz debe ser igual a 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sleeping eating pooping\n",
      "sleeping      0.4    0.2     0.4\n",
      "eating       0.45   0.45     0.1\n",
      "pooping      0.45   0.25     0.3\n",
      "\n",
      " [[0.4 0.2 0.4]\n",
      " [0.45 0.45 0.1]\n",
      " [0.45 0.25 0.3]] (3, 3) \n",
      "\n",
      "sleeping    1.0\n",
      "eating      1.0\n",
      "pooping     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create transition matrix\n",
    "# equals transition probability matrix of changing states given a state\n",
    "# matrix is size (N x N) where N is number of states\n",
    "\n",
    "q_df = pd.DataFrame(columns=states, index=states)\n",
    "q_df.loc[states[0]] = [0.4, 0.2, 0.4]\n",
    "q_df.loc[states[1]] = [0.45, 0.45, 0.1]\n",
    "q_df.loc[states[2]] = [0.45, 0.25, .3]\n",
    "\n",
    "print(q_df)\n",
    "\n",
    "q = q_df.values\n",
    "print('\\n', q, q.shape, '\\n')\n",
    "print(q_df.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible observar todas las combinaciones posibles de estados, dado un estado inicial, junto con la probabilidad de cambiar al estado siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('eating', 'eating'): 0.45,\n",
      " ('eating', 'pooping'): 0.1,\n",
      " ('eating', 'sleeping'): 0.45,\n",
      " ('pooping', 'eating'): 0.25,\n",
      " ('pooping', 'pooping'): 0.3,\n",
      " ('pooping', 'sleeping'): 0.45,\n",
      " ('sleeping', 'eating'): 0.2,\n",
      " ('sleeping', 'pooping'): 0.4,\n",
      " ('sleeping', 'sleeping'): 0.4}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "# create a function that maps transition probability dataframe \n",
    "# to markov edges and weights\n",
    "\n",
    "def _get_markov_edges(Q):\n",
    "    edges = {}\n",
    "    for col in Q.columns:\n",
    "        for idx in Q.index:\n",
    "            edges[(idx,col)] = Q.loc[idx,col]\n",
    "    return edges\n",
    "\n",
    "edges_wts = _get_markov_edges(q_df)\n",
    "pprint(edges_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diagrama de estados se observa a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static1.squarespace.com/static/53ac905ee4b003339a856a1d/t/58acd0f217bffc7d4100d6e3/1487720703303/?format=500w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modelo Oculto de Markov\n",
    "\n",
    "El modelo anterior describe una simple máquina de estados donde el perro puede estar haciendo diferentes actividades. Se puede considerar que el perro hace alguna actividad debido a un estado oculto que no conocemos, en este caso, que puede estar sano o enfermo. Con esto, las actividades del perro se convierten en las observaciones y su estado de salud en los estados ocultos.\n",
    "\n",
    "De esta manera se implementa el nuevo vector pi de estado inicial. Para este caso se asigna que el perro puede estar inicialmente sano o enfermo con la misma probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy    0.5\n",
      "sick       0.5\n",
      "Name: states, dtype: float64\n",
      "\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# create state space and initial state probabilities\n",
    "\n",
    "hidden_states = ['healthy', 'sick']\n",
    "pi_hmm = [0.5, 0.5]\n",
    "state_space = pd.Series(pi_hmm, index=hidden_states, name='states')\n",
    "print(state_space)\n",
    "print('\\n', state_space.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los estados ocultos ahora son que el perro está sano o enfermo, con lo que se genera la nueva matrix A de densidad de probabilidad de transición de estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        healthy sick\n",
      "healthy     0.7  0.3\n",
      "sick        0.4  0.6\n",
      "healthy    1.0\n",
      "sick       1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create hidden transition matrix\n",
    "# a or alpha \n",
    "#   = transition probability matrix of changing states given a state\n",
    "# matrix is size (N x N) where M is number of states\n",
    "\n",
    "a_df = pd.DataFrame(columns=hidden_states, index=hidden_states)\n",
    "a_df.loc[hidden_states[0]] = [0.7, 0.3]\n",
    "a_df.loc[hidden_states[1]] = [0.4, 0.6]\n",
    "\n",
    "print(a_df)\n",
    "\n",
    "a = a_df.values\n",
    "print(a_df.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente se crea la matriz B de distribución de probabilidad de observación en el estado j. Esta matriz es de tamaño NxO en donde N es el número de estados (sano, enfermo) y O el número de observaciones (jugando, durmiendo, comiendo). Esta matriz indica la probabilidad de que el perro esté en un estado oculto, dada la observación actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sleeping eating pooping\n",
      "healthy      0.2    0.6     0.2\n",
      "sick         0.4    0.1     0.5\n",
      "healthy    1.0\n",
      "sick       1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create matrix of observation (emission) probabilities\n",
    "# b or beta = observation probabilities given state\n",
    "# matrix is size (N x O) where N is number of states \n",
    "# and O is number of different possible observations\n",
    "\n",
    "observable_states = states\n",
    "\n",
    "b_df = pd.DataFrame(columns=observable_states, index=hidden_states)\n",
    "b_df.loc[hidden_states[0]] = [0.2, 0.6, 0.2]\n",
    "b_df.loc[hidden_states[1]] = [0.4, 0.1, 0.5]\n",
    "\n",
    "print(b_df)\n",
    "\n",
    "b = b_df.values\n",
    "print(b_df.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible imprimir las matrices para poder observar la probabilidad entre las observaciones y los estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('healthy', 'healthy'): 0.7,\n",
      " ('healthy', 'sick'): 0.3,\n",
      " ('sick', 'healthy'): 0.4,\n",
      " ('sick', 'sick'): 0.6}\n",
      "{('healthy', 'eating'): 0.6,\n",
      " ('healthy', 'pooping'): 0.2,\n",
      " ('healthy', 'sleeping'): 0.2,\n",
      " ('sick', 'eating'): 0.1,\n",
      " ('sick', 'pooping'): 0.5,\n",
      " ('sick', 'sleeping'): 0.4}\n"
     ]
    }
   ],
   "source": [
    "# create graph edges and weights\n",
    "\n",
    "hide_edges_wts = _get_markov_edges(a_df)\n",
    "pprint(hide_edges_wts)\n",
    "\n",
    "emit_edges_wts = _get_markov_edges(b_df)\n",
    "pprint(emit_edges_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diagrama de estados se observa a continuaciónn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static1.squarespace.com/static/53ac905ee4b003339a856a1d/t/58ace1001b10e36e94edce9c/1487724814740/?format=1000w)\n",
    "\n",
    "Ahora se puede aplicar la solución de problemas de HMM para encontrar el estado más probable, dada una observación del comportamiento del perro. Para esto se hace una lista de O observaciones y se le asigna un código a cada comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Obs_code   Obs_seq\n",
      "0         1    eating\n",
      "1         1    eating\n",
      "2         2   pooping\n",
      "3         1    eating\n",
      "4         0  sleeping\n",
      "5         1    eating\n",
      "6         2   pooping\n",
      "7         1    eating\n",
      "8         0  sleeping\n",
      "9         2   pooping\n",
      "10        2   pooping\n",
      "11        0  sleeping\n",
      "12        1    eating\n",
      "13        0  sleeping\n",
      "14        1    eating\n"
     ]
    }
   ],
   "source": [
    "# observation sequence of dog's behaviors\n",
    "# observations are encoded numerically\n",
    "\n",
    "obs_map = {'sleeping':0, 'eating':1, 'pooping':2}\n",
    "obs = np.array([1,1,2,1,0,1,2,1,0,2,2,0,1,0,1])\n",
    "\n",
    "inv_obs_map = dict((v,k) for k, v in obs_map.items())\n",
    "obs_seq = [inv_obs_map[v] for v in list(obs)]\n",
    "\n",
    "print( pd.DataFrame(np.column_stack([obs, obs_seq]), \n",
    "                columns=['Obs_code', 'Obs_seq']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la aplicación del algoritmo de Viterbi se puede hallar la secuencia más probable de estados escondidos dada la secuencia de observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Viterbi algorithm for shortest path\n",
    "# code adapted from Stephen Marsland's, Machine Learning An Algorthmic Perspective, Vol. 2\n",
    "# https://github.com/alexsosn/MarslandMLAlgo/blob/master/Ch16/HMM.py\n",
    "\n",
    "def viterbi(pi, a, b, obs):\n",
    "    \n",
    "    nStates = np.shape(b)[0]\n",
    "    T = np.shape(obs)[0]\n",
    "    \n",
    "    # init blank path\n",
    "    path = np.zeros(T)\n",
    "    # delta --> highest probability of any path that reaches state i\n",
    "    delta = np.zeros((nStates, T))\n",
    "    # phi --> argmax by time step for each state\n",
    "    phi = np.zeros((nStates, T))\n",
    "    \n",
    "    # init delta and phi \n",
    "    delta[:, 0] = pi * b[:, obs[0]]\n",
    "    phi[:, 0] = 0\n",
    "\n",
    "    print('\\nStart Walk Forward\\n')    \n",
    "    # the forward algorithm extension\n",
    "    for t in range(1, T):\n",
    "        for s in range(nStates):\n",
    "            delta[s, t] = np.max(delta[:, t-1] * a[:, s]) * b[s, obs[t]]\n",
    "            phi[s, t] = np.argmax(delta[:, t-1] * a[:, s])\n",
    "            print('s={s} and t={t}: phi[{s}, {t}] = {phi}'.format(s=s, t=t, phi=phi[s, t]))\n",
    "    \n",
    "    # find optimal path\n",
    "    print('-'*50)\n",
    "    print('Start Backtrace\\n')\n",
    "    path[T-1] = np.argmax(delta[:, T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        path[t] = phi[int(path[t+1]), [t+1]]\n",
    "        print('path[{}] = {}'.format(t, path[t]))\n",
    "        \n",
    "    return path, delta, phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se llama al algoritmo de Viterbi, con las observaciones realizadas y las matrices de probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Walk Forward\n",
      "\n",
      "s=0 and t=1: phi[0, 1] = 0.0\n",
      "s=1 and t=1: phi[1, 1] = 0.0\n",
      "s=0 and t=2: phi[0, 2] = 0.0\n",
      "s=1 and t=2: phi[1, 2] = 0.0\n",
      "s=0 and t=3: phi[0, 3] = 0.0\n",
      "s=1 and t=3: phi[1, 3] = 1.0\n",
      "s=0 and t=4: phi[0, 4] = 0.0\n",
      "s=1 and t=4: phi[1, 4] = 0.0\n",
      "s=0 and t=5: phi[0, 5] = 0.0\n",
      "s=1 and t=5: phi[1, 5] = 1.0\n",
      "s=0 and t=6: phi[0, 6] = 0.0\n",
      "s=1 and t=6: phi[1, 6] = 0.0\n",
      "s=0 and t=7: phi[0, 7] = 0.0\n",
      "s=1 and t=7: phi[1, 7] = 1.0\n",
      "s=0 and t=8: phi[0, 8] = 0.0\n",
      "s=1 and t=8: phi[1, 8] = 0.0\n",
      "s=0 and t=9: phi[0, 9] = 0.0\n",
      "s=1 and t=9: phi[1, 9] = 1.0\n",
      "s=0 and t=10: phi[0, 10] = 1.0\n",
      "s=1 and t=10: phi[1, 10] = 1.0\n",
      "s=0 and t=11: phi[0, 11] = 1.0\n",
      "s=1 and t=11: phi[1, 11] = 1.0\n",
      "s=0 and t=12: phi[0, 12] = 1.0\n",
      "s=1 and t=12: phi[1, 12] = 1.0\n",
      "s=0 and t=13: phi[0, 13] = 0.0\n",
      "s=1 and t=13: phi[1, 13] = 0.0\n",
      "s=0 and t=14: phi[0, 14] = 0.0\n",
      "s=1 and t=14: phi[1, 14] = 1.0\n",
      "--------------------------------------------------\n",
      "Start Backtrace\n",
      "\n",
      "path[13] = 0.0\n",
      "path[12] = 0.0\n",
      "path[11] = 1.0\n",
      "path[10] = 1.0\n",
      "path[9] = 1.0\n",
      "path[8] = 1.0\n",
      "path[7] = 0.0\n",
      "path[6] = 0.0\n",
      "path[5] = 0.0\n",
      "path[4] = 0.0\n",
      "path[3] = 0.0\n",
      "path[2] = 0.0\n",
      "path[1] = 0.0\n",
      "path[0] = 0.0\n"
     ]
    }
   ],
   "source": [
    "path, delta, phi = viterbi(pi_hmm, a, b, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "single best state path: \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "delta:\n",
      " [[3.00000000e-01 1.26000000e-01 1.76400000e-02 7.40880000e-03\n",
      "  1.03723200e-03 4.35637440e-04 6.09892416e-05 2.56154815e-05\n",
      "  3.58616741e-06 5.02063437e-07 7.37725866e-08 2.21317760e-08\n",
      "  1.59348787e-08 2.23088302e-09 9.36970868e-10]\n",
      " [5.00000000e-02 9.00000000e-03 1.89000000e-02 1.13400000e-03\n",
      "  8.89056000e-04 5.33433600e-05 6.53456160e-05 3.92073696e-06\n",
      "  3.07385778e-06 9.22157333e-07 2.76647200e-07 6.63953280e-08\n",
      "  3.98371968e-09 1.91218545e-09 1.14731127e-10]]\n",
      "phi:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nsingle best state path: \\n', path)\n",
    "print('delta:\\n', delta)\n",
    "print('phi:\\n', phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se pueden tabular los resultados con la observación inicial y los estados encontrados por el algoritmo de Viterbi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation</th>\n",
       "      <th>Best_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pooping</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pooping</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pooping</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pooping</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eating</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Observation Best_Path\n",
       "0       eating   healthy\n",
       "1       eating   healthy\n",
       "2      pooping   healthy\n",
       "3       eating   healthy\n",
       "4     sleeping   healthy\n",
       "5       eating   healthy\n",
       "6      pooping   healthy\n",
       "7       eating   healthy\n",
       "8     sleeping      sick\n",
       "9      pooping      sick\n",
       "10     pooping      sick\n",
       "11    sleeping      sick\n",
       "12      eating   healthy\n",
       "13    sleeping   healthy\n",
       "14      eating   healthy"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_map = {0:'healthy', 1:'sick'}\n",
    "state_path = [state_map[v] for v in path]\n",
    "\n",
    "(pd.DataFrame()\n",
    " .assign(Observation=obs_seq)\n",
    " .assign(Best_Path=state_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones\n",
    "\n",
    "En este notebook se presentó la teoría que describe al Modelo Oculto de Markov y se presentó un ejemplo simple en donde se modela el comportamiento de un perro de acuerdo a los estados ocultos de si el perro está sano o enfermo, mediante el algoritmo de Viterbi.\n",
    "\n",
    "Como trabajo futuro se puede implementar un sistema de reconocimiento de voz mediante la solución a los tres problemas de Markov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "[1] [Foundations of Statistical Natural Language Processing](https://www.cs.vassar.edu/~cs366/docs/Manning_Schuetze_StatisticalNLP.pdf)\n",
    "\n",
    "[2] [An Introduction to Hidden Markov Model](http://ai.stanford.edu/~pabbeel/depth_qual/Rabiner_Juang_hmms.pdf)\n",
    "\n",
    "[3] [Introduction to Hidden Markov Models with Python Networkx and Sklearn](http://www.blackarbs.com/blog/introduction-hidden-markov-models-python-networkx-sklearn/2/9/2017)\n",
    "\n",
    "[4] [Introduction to Hidden Markov Model](http://www.adeveloperdiary.com/data-science/machine-learning/introduction-to-hidden-markov-model/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
